import time
from io import BytesIO
import asyncio
import logging
import soundfile as sf
import numpy as np
import speech_recognition as sr
import sounddevice as sd
from collections import deque
from threading import Lock
from Logger import logger
import httpx
import json
class AudioState:
    def __init__(self):
        self.is_recording = False
        self.audio_buffer = []
        self.last_sound_time = time.time()
        self.is_playing = False
        self.lock = asyncio.Lock()
        self.vc = None
        self.max_buffer_size = 9999999

    async def add_to_buffer(self, data):
        async with self.lock:
            if len(self.audio_buffer) >= self.max_buffer_size:
                self.audio_buffer = self.audio_buffer[-self.max_buffer_size // 2:]  # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 50%
            self.audio_buffer.append(data.copy())


audio_state = AudioState()


class SpeechRecognition:
    user_input = ""
    microphone_index = 0
    active = True
    _recognizer_type = "google"  # 'google' Ð¸Ð»Ð¸ 'vosk'
    vosk_model = "vosk-model-ru-0.10" #vosk-model-small-ru

    SAMPLE_RATE = 44000
    CHUNK_SIZE = 512
    TIMEOUT_MESSAGE = True
    SILENCE_THRESHOLD = 0.02  # ÐŸÐ¾Ñ€Ð¾Ð³ Ñ‚Ð¸ÑˆÐ¸Ð½Ñ‹
    SILENCE_DURATION = 4  # Ð”Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ñ‚Ð¸ÑˆÐ¸Ð½Ñ‹ Ð´Ð»Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ñ Ð·Ð°Ð¿Ð¸ÑÐ¸
    SILENCE_TIMEOUT = 2.0
    MIN_RECORDING = 1.0
    MIN_RECORDING_DURATION = 1  # ÐœÐ¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ð°Ñ Ð´Ð»Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð·Ð°Ð¿Ð¸ÑÐ¸
    BUFFER_TIMEOUT = 0.05
    VOSK_PROCESS_INTERVAL = 0.1 # Ð˜Ð½Ñ‚ÐµÑ€Ð²Ð°Ð» Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Vosk (ÑÐµÐº)
    _text_lock = Lock()
    _text_buffer = deque(maxlen=10)  # Ð¥Ñ€Ð°Ð½Ð¸Ð¼ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ 10 Ñ„Ñ€Ð°Ð·
    _current_text = ""
    _last_delimiter = ". "

    @staticmethod
    def set_recognizer_type(recognizer_type: str):
        if recognizer_type in ["google", "vosk"]:
            SpeechRecognition._recognizer_type = recognizer_type
            logger.info(f"Ð¢Ð¸Ð¿ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ñ‚ÐµÐ»Ñ ÑƒÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½ Ð½Ð°: {recognizer_type}")
        else:
            logger.warning(f"ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ñ‹Ð¹ Ñ‚Ð¸Ð¿ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ñ‚ÐµÐ»Ñ: {recognizer_type}. Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ 'google'.")


    @staticmethod
    def receive_text() -> str:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸ ÑÐ±Ñ€Ð¾Ñ Ñ‚ÐµÐºÑÑ‚Ð° (ÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ñ‹Ð¹ Ð¼ÐµÑ‚Ð¾Ð´)"""
        with SpeechRecognition._text_lock:
            result = " ".join(SpeechRecognition._text_buffer).strip()
            SpeechRecognition._text_buffer.clear()
            SpeechRecognition._current_text = ""
            #logger.debug(f"Returned text: {result}")
            return result

    @staticmethod
    def list_microphones():
        return sr.Microphone.list_microphone_names()

    @staticmethod
    async def handle_voice_message(recognized_text: str) -> None:
        """ÐÑÐ¸Ð½Ñ…Ñ€Ð¾Ð½Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ‚ÐµÐºÑÑ‚Ð°"""
        text_clean = recognized_text.strip()
        if text_clean:
            with SpeechRecognition._text_lock:
                # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ Ñ€Ð°Ð·Ð´ÐµÐ»Ð¸Ñ‚ÐµÐ»Ñ
                last_char = SpeechRecognition._current_text[-1] if SpeechRecognition._current_text else ""
                delimiter = "" if last_char in {'.', '!', '?', ','} else " "

                SpeechRecognition._text_buffer.append(text_clean)
                SpeechRecognition._current_text += f"{delimiter}{text_clean}"

    @staticmethod
    async def recognize_vosk(audio_data: np.ndarray) -> str | None:
        """Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ Ñ€ÐµÑ‡Ð¸ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Vosk API."""
        try:
            # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ð½Ð¸Ðµ numpy array Ð² BytesIO Ð¾Ð±ÑŠÐµÐºÑ‚ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ WAV
            with BytesIO() as buffer:
                sf.write(buffer, audio_data, SpeechRecognition.SAMPLE_RATE, format='WAV')
                buffer.seek(0)
                audio_bytes = buffer.read()

            async with httpx.AsyncClient() as client:
                # ÐžÑ‚Ð¿Ñ€Ð°Ð²ÐºÐ° Ð°ÑƒÐ´Ð¸Ð¾ Ð½Ð° Vosk API
                response = await client.post(
                    "http://127.0.0.1:8000/vtt/transcribe",  # ÐŸÑ€ÐµÐ´Ð¿Ð¾Ð»Ð°Ð³Ð°ÐµÐ¼, Ñ‡Ñ‚Ð¾ ÑÐµÑ€Ð²ÐµÑ€ Vosk Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ð¾
                    files={"audio_file": ("audio.wav", audio_bytes, "audio/wav")}
                )
                response.raise_for_status()  # Ð’Ñ‹Ð·Ð¾Ð²ÐµÑ‚ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ ÑÑ‚Ð°Ñ‚ÑƒÑÐ¾Ð² 4xx/5xx
                result = response.json()
                text = result.get("text")
                if text:
                    logger.info(f"Vosk Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð»: {text}")
                    return text
                else:
                    logger.warning("Vosk Ð½Ðµ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð» Ñ‚ÐµÐºÑÑ‚.")
                    return None
        except httpx.RequestError as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ñ€Ð¾ÑÐ° Ðº Vosk API: {e}")
            return None
        except json.JSONDecodeError:
            logger.error("ÐžÑˆÐ¸Ð±ÐºÐ° Ð´ÐµÐºÐ¾Ð´Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ JSON Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Vosk API.")
            return None
        except Exception as e:
            logger.error(f"ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ð¸ Vosk: {e}")
            return None

    @staticmethod
    async def live_recognition() -> None:
        # Ð­Ñ‚Ð¾Ñ‚ Ð¼ÐµÑ‚Ð¾Ð´ Ð±ÑƒÐ´ÐµÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð¿Ð¾-Ñ€Ð°Ð·Ð½Ð¾Ð¼Ñƒ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð³Ð¾ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ñ‚ÐµÐ»Ñ.
        # Ð”Ð»Ñ Google Ð±ÑƒÐ´ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ speech_recognition.Microphone.
        # Ð”Ð»Ñ Vosk Ð±ÑƒÐ´ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ sounddevice Ð´Ð»Ñ Ð¿Ñ€ÑÐ¼Ð¾Ð³Ð¾ Ð·Ð°Ñ…Ð²Ð°Ñ‚Ð° Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð² Vosk API.

        if SpeechRecognition._recognizer_type == "google":
            recognizer = sr.Recognizer()
            with sr.Microphone(device_index=SpeechRecognition.microphone_index, sample_rate=SpeechRecognition.SAMPLE_RATE,
                               chunk_size=SpeechRecognition.CHUNK_SIZE) as source:
                logger.info(
                    f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½: {sr.Microphone.list_microphone_names()[SpeechRecognition.microphone_index]}")
                recognizer.adjust_for_ambient_noise(source)
                logger.info("Ð¡ÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ñ‡Ñ‚Ð¾-Ð½Ð¸Ð±ÑƒÐ´ÑŒ (Google)...")

                while SpeechRecognition.active:
                    try:
                        audio = await asyncio.get_event_loop().run_in_executor(
                            None,
                            lambda: recognizer.listen(source, timeout=5)
                        )

                        text = await asyncio.get_event_loop().run_in_executor(
                            None,
                            lambda: recognizer.recognize_google(audio, language="ru-RU")
                        )
                        if not text:
                            text = await asyncio.get_event_loop().run_in_executor(
                                None,
                                lambda: recognizer.recognize_google(audio, language="en-EN")
                            )

                        if text:
                            await SpeechRecognition.handle_voice_message(text)

                    except sr.WaitTimeoutError:
                        if SpeechRecognition.TIMEOUT_MESSAGE:
                            ...
                    except sr.UnknownValueError:
                        ...
                    except Exception as e:
                        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ð¸ Google: {e}")
                        break
    @staticmethod
    async def live_recognition() -> None:
        # Ð­Ñ‚Ð¾Ñ‚ Ð¼ÐµÑ‚Ð¾Ð´ Ð±ÑƒÐ´ÐµÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð¿Ð¾-Ñ€Ð°Ð·Ð½Ð¾Ð¼Ñƒ Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð½Ð¾Ð³Ð¾ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ñ‚ÐµÐ»Ñ.
        # Ð”Ð»Ñ Google Ð±ÑƒÐ´ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ speech_recognition.Microphone.
        # Ð”Ð»Ñ Vosk Ð±ÑƒÐ´ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ sounddevice Ð´Ð»Ñ Ð¿Ñ€ÑÐ¼Ð¾Ð³Ð¾ Ð·Ð°Ñ…Ð²Ð°Ñ‚Ð° Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÐºÐ¸ Ð² Vosk API.

        if SpeechRecognition._recognizer_type == "google":
            recognizer = sr.Recognizer()
            with sr.Microphone(device_index=SpeechRecognition.microphone_index, sample_rate=SpeechRecognition.SAMPLE_RATE,
                               chunk_size=SpeechRecognition.CHUNK_SIZE) as source:
                logger.info(
                    f"Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½: {sr.Microphone.list_microphone_names()[SpeechRecognition.microphone_index]}")
                recognizer.adjust_for_ambient_noise(source)
                logger.info("Ð¡ÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ñ‡Ñ‚Ð¾-Ð½Ð¸Ð±ÑƒÐ´ÑŒ (Google)...")

                while SpeechRecognition.active:
                    try:
                        audio = await asyncio.get_event_loop().run_in_executor(
                            None,
                            lambda: recognizer.listen(source, timeout=5)
                        )

                        text = await asyncio.get_event_loop().run_in_executor(
                            None,
                            lambda: recognizer.recognize_google(audio, language="ru-RU")
                        )
                        if not text:
                            text = await asyncio.get_event_loop().run_in_executor(
                                None,
                                lambda: recognizer.recognize_google(audio, language="en-EN")
                            )

                        if text:
                            await SpeechRecognition.handle_voice_message(text)

                    except sr.WaitTimeoutError:
                        if SpeechRecognition.TIMEOUT_MESSAGE:
                            ...
                    except sr.UnknownValueError:
                        ...
                    except Exception as e:
                        logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ð¸ Google: {e}")
                        break
        elif SpeechRecognition._recognizer_type == "vosk":
            logger.info(f"Ð¡ÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ñ‡Ñ‚Ð¾-Ð½Ð¸Ð±ÑƒÐ´ÑŒ (Vosk)... ÐœÐ¾Ð´ÐµÐ»ÑŒ: {SpeechRecognition.vosk_model}")
            # Ð”Ð»Ñ Vosk Ð¼Ñ‹ Ð±ÑƒÐ´ÐµÐ¼ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ sounddevice Ð´Ð»Ñ Ð½ÐµÐ¿Ñ€ÐµÑ€Ñ‹Ð²Ð½Ð¾Ð³Ð¾ Ð·Ð°Ñ…Ð²Ð°Ñ‚Ð°
            # Ð¸ Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑ‚ÑŒ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² Vosk API.
            # Ð’Ð½ÐµÐ´Ñ€ÑÐµÐ¼ VAD (Voice Activity Detection) Ð´Ð»Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ ÐºÐ¾Ð½Ñ†Ð° Ñ€ÐµÑ‡Ð¸.

            vosk_live_audio_buffer = []
            is_vosk_recording = False
            last_sound_time_vosk = time.time()

            async def vosk_live_callback(indata, frames, time_info, status):
                nonlocal is_vosk_recording, last_sound_time_vosk
                if status:
                    logger.warning(f"Vosk live callback status: {status}")

                rms = np.sqrt(np.mean(indata ** 2))
                current_time = time.time()

                if rms > SpeechRecognition.SILENCE_THRESHOLD:
                    last_sound_time_vosk = current_time
                    if not is_vosk_recording:
                        logger.debug("ðŸŸ¢ ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð·Ð°Ð¿Ð¸ÑÐ¸ (Vosk live)")
                        is_vosk_recording = True
                    vosk_live_audio_buffer.append(indata.copy())
                elif is_vosk_recording and (current_time - last_sound_time_vosk > SpeechRecognition.SILENCE_DURATION):
                    logger.debug("ðŸ”´ ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð° Ñ‚Ð¸ÑˆÐ¸Ð½Ð°, Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¸Ðµ Ð·Ð°Ð¿Ð¸ÑÐ¸ (Vosk live)")
                    is_vosk_recording = False
                    if vosk_live_audio_buffer:
                        audio_data_to_process = np.concatenate(vosk_live_audio_buffer)
                        vosk_live_audio_buffer.clear()
                        asyncio.create_task(SpeechRecognition.recognize_vosk(audio_data_to_process))
                        await asyncio.sleep(SpeechRecognition.VOSK_PROCESS_INTERVAL)  # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð° Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ°
                elif is_vosk_recording: # ÐŸÑ€Ð¾Ð´Ð¾Ð»Ð¶Ð°ÐµÐ¼ Ð·Ð°Ð¿Ð¸ÑÑŒ, ÐµÑÐ»Ð¸ Ð·Ð²ÑƒÐº Ð½Ð¸Ð¶Ðµ Ð¿Ð¾Ñ€Ð¾Ð³Ð°, Ð½Ð¾ Ñ‚Ð¸ÑˆÐ¸Ð½Ð° ÐµÑ‰Ðµ Ð½Ðµ Ð´Ð¾ÑÑ‚Ð¸Ð³Ð»Ð° SILENCE_DURATION
                    vosk_live_audio_buffer.append(indata.copy())
                    await asyncio.sleep(SpeechRecognition.VOSK_PROCESS_INTERVAL)  # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð° Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ°
                else: # Ð•ÑÐ»Ð¸ Ð½Ðµ Ð·Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÐ¼ Ð¸ Ð½ÐµÑ‚ Ð·Ð²ÑƒÐºÐ°, Ð¾Ñ‡Ð¸Ñ‰Ð°ÐµÐ¼ Ð±ÑƒÑ„ÐµÑ€, ÐµÑÐ»Ð¸ Ñ‚Ð°Ð¼ Ñ‡Ñ‚Ð¾-Ñ‚Ð¾ ÐµÑÑ‚ÑŒ
                    if vosk_live_audio_buffer:
                        logger.debug("âŒ Ð¡Ð»Ð¸ÑˆÐºÐ¾Ð¼ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ°Ñ Ð·Ð°Ð¿Ð¸ÑÑŒ Ð¸Ð»Ð¸ Ð»Ð¾Ð¶Ð½Ð°Ñ Ð°ÐºÑ‚Ð¸Ð²Ð°Ñ†Ð¸Ñ, ÑÐ±Ñ€Ð¾Ñ (Vosk live)")
                        vosk_live_audio_buffer.clear()
                    await asyncio.sleep(SpeechRecognition.VOSK_PROCESS_INTERVAL)  # Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð° Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ°

            try:
                def start_stream():
                    with sd.RawInputStream(
                            callback=vosk_live_callback,
                            channels=1,
                            samplerate=SpeechRecognition.SAMPLE_RATE,
                            blocksize=SpeechRecognition.CHUNK_SIZE,
                            dtype='float32',
                            device=SpeechRecognition.microphone_index
                    ):
                        while SpeechRecognition.active:
                            time.sleep(0.001)

                import threading
                thread = threading.Thread(target=start_stream)
                thread.start()

                while SpeechRecognition.active:
                    await asyncio.sleep(0.1)  # ÐÐµÐ±Ð¾Ð»ÑŒÑˆÐ°Ñ Ð·Ð°Ð´ÐµÑ€Ð¶ÐºÐ° Ð´Ð»Ñ Ñ†Ð¸ÐºÐ»Ð°
            except Exception as e:
                logger.critical(f"ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ° Ð² live_recognition (Vosk): {str(e)}")

    @staticmethod
    async def async_audio_callback(indata):
        try:
            current_time = time.time()
            rms = np.sqrt(np.mean(indata ** 2))

            async with audio_state.lock:
                if rms > SpeechRecognition.SILENCE_THRESHOLD:
                    audio_state.last_sound_time = current_time
                    if not audio_state.is_recording:
                        logger.debug("ðŸŸ¢ ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð·Ð°Ð¿Ð¸ÑÐ¸")
                        audio_state.is_recording = True
                    await audio_state.add_to_buffer(indata)

                elif audio_state.is_recording:
                    silence_duration = 4
                    audio_state.is_recording = False
                    await SpeechRecognition.process_audio()
                else:
                    logger.debug("âŒ Ð¡Ð»Ð¸ÑˆÐºÐ¾Ð¼ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ°Ñ Ð·Ð°Ð¿Ð¸ÑÑŒ, ÑÐ±Ñ€Ð¾Ñ")
                    audio_state.audio_buffer.clear()
                    audio_state.is_recording = False

        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð² ÐºÐ¾Ð»Ð±ÑÐºÐµ: {str(e)}")

    @staticmethod
    async def process_audio():
        try:
            async with audio_state.lock:
                if not audio_state.audio_buffer:
                    return

                audio_data = np.concatenate(audio_state.audio_buffer)
                audio_state.audio_buffer.clear()

                text = None
                if SpeechRecognition._recognizer_type == "google":
                    with BytesIO() as buffer:
                        sf.write(buffer, audio_data, SpeechRecognition.SAMPLE_RATE, format='WAV')
                        buffer.seek(0)

                        try:
                            recognizer = sr.Recognizer()
                            with sr.AudioFile(buffer) as source:
                                audio = recognizer.record(source)
                                text = recognizer.recognize_google(audio, language="ru-RU")
                                logger.info(f"Google Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð»: {text}")
                        except sr.UnknownValueError:
                            logger.warning("Google Ð½Ðµ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð» Ñ€ÐµÑ‡ÑŒ.")
                        except Exception as e:
                            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ Google: {str(e)}")
                elif SpeechRecognition._recognizer_type == "vosk":
                    text = await SpeechRecognition.recognize_vosk(audio_data)

                if text:
                    await SpeechRecognition.handle_voice_message(text)
        except Exception as e:
            logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸: {str(e)}")

    @staticmethod
    async def recognize_speech(audio_buffer):
        # Ð­Ñ‚Ð¾Ñ‚ Ð¼ÐµÑ‚Ð¾Ð´ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ Ð´Ð»Ñ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ Ð¸Ð· Ð±ÑƒÑ„ÐµÑ€Ð°,
        # ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ ÑƒÐ¶Ðµ ÑÐ²Ð»ÑÐµÑ‚ÑÑ AudioFile-Ð¿Ð¾Ð´Ð¾Ð±Ð½Ñ‹Ð¼ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð¼.
        # Ð”Ð»Ñ Vosk API Ð½Ð°Ð¼ Ð½ÑƒÐ¶ÐµÐ½ numpy array.
        # ÐŸÐ¾ÑÑ‚Ð¾Ð¼Ñƒ, ÐµÑÐ»Ð¸ Ð²Ñ‹Ð±Ñ€Ð°Ð½ Vosk, Ð½ÑƒÐ¶Ð½Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ñ‚ÑŒ audio_buffer Ð² numpy array.
        # Ð˜Ð»Ð¸ Ð¶Ðµ ÑÑ‚Ð¾Ñ‚ Ð¼ÐµÑ‚Ð¾Ð´ Ð±ÑƒÐ´ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð»Ñ Google.
        # ÐŸÐ¾ÐºÐ° Ð¾ÑÑ‚Ð°Ð²Ð¸Ð¼ ÐµÐ³Ð¾ Ð´Ð»Ñ Google, Ñ‚Ð°Ðº ÐºÐ°Ðº Ð¾Ð½ Ð¿Ñ€Ð¸Ð½Ð¸Ð¼Ð°ÐµÑ‚ AudioFile.
        # Ð•ÑÐ»Ð¸ Ð¿Ð¾Ñ‚Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Vosk Ð·Ð´ÐµÑÑŒ, Ð½ÑƒÐ¶Ð½Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð¿ÐµÑ€ÐµÑÐ¼Ð¾Ñ‚Ñ€ÐµÑ‚ÑŒ.
        recognizer = sr.Recognizer()
        text = None

        if SpeechRecognition._recognizer_type == "google":
            try:
                with sr.AudioFile(audio_buffer) as source:
                    audio = recognizer.record(source)

                text = recognizer.recognize_google(audio, language="ru-RU")
                if not text:
                    text = recognizer.recognize_google(audio, language="en-EN")
                return text
            except sr.UnknownValueError:
                logger.error("Google: ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ Ñ€ÐµÑ‡ÑŒ")
                return None
            except sr.RequestError as e:
                logger.error(f"Google: ÐžÑˆÐ¸Ð±ÐºÐ° API: {e}")
                return None
        elif SpeechRecognition._recognizer_type == "vosk":
            # Ð—Ð´ÐµÑÑŒ Ð½ÑƒÐ¶Ð½Ð¾ Ð±ÑƒÐ´ÐµÑ‚ Ð¿Ñ€ÐµÐ¾Ð±Ñ€Ð°Ð·Ð¾Ð²Ð°Ñ‚ÑŒ audio_buffer Ð² numpy array
            # Ð­Ñ‚Ð¾ ÑÐ»Ð¾Ð¶Ð½ÐµÐµ, Ñ‚Ð°Ðº ÐºÐ°Ðº audio_buffer Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ BytesIO Ð¸Ð»Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ð¼ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð¼
            # Ð”Ð»Ñ Ð¿Ñ€Ð¾ÑÑ‚Ð¾Ñ‚Ñ‹, Ð¿Ð¾ÐºÐ° ÑÑ‚Ð¾Ñ‚ Ð¼ÐµÑ‚Ð¾Ð´ Ð±ÑƒÐ´ÐµÑ‚ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ñ Google
            logger.warning("recognize_speech Ð½Ðµ Ð¿Ð¾Ð´Ð´ÐµÑ€Ð¶Ð¸Ð²Ð°ÐµÑ‚ Vosk Ð½Ð°Ð¿Ñ€ÑÐ¼ÑƒÑŽ Ñ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¼ Ñ‚Ð¸Ð¿Ð¾Ð¼ audio_buffer.")
            return None

    @staticmethod
    async def speach_recognition_start_async_other_system():
        while SpeechRecognition.active:
            try:
                await SpeechRecognition.async_audio_callback(0)
                await asyncio.sleep(0.1)  # Ð£Ð¼ÐµÐ½ÑŒÑˆÐ¸Ð¼ Ð¸Ð½Ñ‚ÐµÑ€Ð²Ð°Ð»
            except Exception as e:
                logger.error(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð² speach_recognition_start_async_other_system: {e}")

    @staticmethod
    async def speach_recognition_start_async():
        await SpeechRecognition.live_recognition()

    @staticmethod
    def speach_recognition_start(device_id: int, loop):
        SpeechRecognition.microphone_index = device_id
        asyncio.run_coroutine_threadsafe(SpeechRecognition.speach_recognition_start_async(), loop)


    @staticmethod
    async def audio_monitoring():
        try:
            logger.info("ðŸš€ Ð—Ð°Ð¿ÑƒÑÐº Ð°ÑƒÐ´Ð¸Ð¾Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³Ð°")
            with sd.InputStream(
                    callback=lambda indata, *_: asyncio.create_task(SpeechRecognition.async_audio_callback(indata)),
                    channels=1,
                    samplerate=SpeechRecognition.SAMPLE_RATE,
                    blocksize=SpeechRecognition.CHUNK_SIZE,
                    device=SpeechRecognition.microphone_index
            ):
                while SpeechRecognition.active:
                    await asyncio.sleep(0.1)
        except Exception as e:
            logger.critical(f"ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¾ÑˆÐ¸Ð±ÐºÐ°: {str(e)}")

    @staticmethod
    async def get_current_text() -> str:
        async with SpeechRecognition._text_lock:
            return SpeechRecognition._current_text.strip()
